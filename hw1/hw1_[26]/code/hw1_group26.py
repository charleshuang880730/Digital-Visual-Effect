# -*- coding: utf-8 -*-
"""VFX_2023_HW1_Group26.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bh5INYXdF4pgMm5NBNPrJiUvTrFHp2Tt
"""


"""### Load Image"""

import glob
import cv2
import numpy as np
def load_img(dir):
  path = sorted(glob.glob(dir + '/*JPG'))
  imgs_B = []
  imgs_G = []
  imgs_R = []
  for file in path:
    print(file)
    img = cv2.imread(file)
    print(img.shape)
    B, G, R = cv2.split(img)
    imgs_B.append(B)
    imgs_G.append(G)
    imgs_R.append(R)
  return imgs_B, imgs_G, imgs_R

"""
Compute G Curve
"""
# constraint weighting function

def weight_func(val):
    if val <= 255//2:
      return val
    else:
      return 255 - val

import math

# Flatten the 2D image array into 1D array, and then sample them uniformly. Also, compute the W simultaneously.

def sample_img(imgs):
  NperDim = math.ceil((255 / len(imgs) * 2) ** (1/2)) # 不知道這是什麼
  N = NperDim ** 2
  print("N: ",N)
  print("img lens: ", len(imgs))
  input()
  Z = np.zeros((len(imgs),N))
  W = np.zeros((len(imgs),N))
  step = imgs[0].shape[1] * imgs[0].shape[0] // N
  for i in range(len(imgs)):
    for j in range(N):
      img = imgs[i].flatten()
      W[i,j] = weight_func(img[step * j])
      Z[i,j] = img[step * j]
  return W,Z

import matplotlib.pyplot as plt
def compute_g_curve(Z, Shutter_time, W, lam = 10):
  print("This is Z: ", Z)
  print("This is Z shape: ", Z.shape[0], Z.shape[1])
  print("This is W: ", W)
  constraint = 255//2
  W = W.flatten('F')
  St = np.log(np.array(Shutter_time)) # log delta ti
  # Create the matrix
  M_A = np.zeros([Z.shape[0] * Z.shape[1] + 255,256 + Z.shape[1]])
  Vec_B = np.zeros([Z.shape[0] * Z.shape[1] + 255,1])
  rows = np.arange(Z.shape[0] * Z.shape[1]).astype(int)
  cols = np.array(Z).flatten('F').astype(int)
  print("This is rows: ", rows)
  print("This is cols: ", cols)
  # print(rows.shape)
  # print(cols)
  input()
  
  # Start to insert the value to the matrix
  # Top left
  M_A[rows, cols] = W
  # Top right
  for n in range(Z.shape[1]):
    # print(Z.shape[0]*n+Z.shape[0])
    tmp = np.zeros((Z.shape[0],Z.shape[1]))
    tmp[:,n] = W[Z.shape[0]*n:Z.shape[0]*n+Z.shape[0]]
    M_A[Z.shape[0]*n:Z.shape[0]*n+Z.shape[0],256:] = -tmp
    Vec_B[Z.shape[0]*n:Z.shape[0]*n+Z.shape[0],0] = St * W[Z.shape[0]*n:Z.shape[0]*n+Z.shape[0]]

  # Bottom left
  for i in range(1,255):
    M_A[Z.shape[0] * Z.shape[1] + i, i-1:i+2] = np.array([1,-2,1]) * lam * weight_func(i)
  # Constraint
  M_A[Z.shape[0] * Z.shape[1],255//2-1] = 1
  # Solving
  x = np.linalg.lstsq(M_A.astype(np.float64), Vec_B.astype(np.float64), rcond=-1)[0]
  g = x[:256]
  lE = x[256:]
  plt.plot([i for i in range(256)],g)
  # print("ln E", lE)
  return g, lE

"""Compute Randiance Map"""

def comput_radiance(imgs, g, Shutter_time):

  # 1 faster 
  localImgs = imgs.copy()
  RadMap = np.zeros((imgs[0].shape[0],imgs[0].shape[1]))
  RadMap = RadMap.flatten()
  Total_w = np.zeros((imgs[0].shape[0],imgs[0].shape[1])).flatten()
  St = np.log(np.array(Shutter_time))
  vfunc = np.vectorize(weight_func)
  
  for p in range(len(imgs)):
    localImgs[p] = localImgs[p].flatten()
  for p in range(len(imgs)):
    imgs_g = np.zeros(RadMap.shape)
    imgs_g[:] = g[localImgs[p],0]
    RadMap += vfunc(localImgs[p]) * (imgs_g - St[p])
    Total_w += vfunc(localImgs[p])
  Total_w[Total_w == 0] = 1
  RadMap /= Total_w
  RadMap = RadMap.reshape(imgs[0].shape)



  # 2 very slow method
  # RadMap = np.zeros((imgs[0].shape[0],imgs[0].shape[1]))
  # St = np.log(np.array(Shutter_time))
  # for y in range(imgs[0].shape[0]):
  #   for x in range(imgs[0].shape[1]):
  #     Total_w = 0
  #     for p in range(len(imgs)):
  #       RadMap[y,x] += weight_func(imgs[p][y,x])*(g[imgs[p][y,x]] - St[p])
  #       Total_w += weight_func(imgs[p][y,x])
  #     RadMap[y,x] /= Total_w

  return RadMap

"""Image alignment"""

import os
import glob
import cv2
import numpy as np
import matplotlib.pyplot as plt

def MTB(ref_img, cmp_img, x, y, threshold):

    h, w = ref_img.shape[:2]

    # 計算參考圖片的 median 並設定 threshold
    ref_median = np.median(ref_img)
    ref_mtb_img, ref_mtb = cv2.threshold(ref_img, ref_median, 255, cv2.THRESH_BINARY)

    # 設定9個平移方向
    bias = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 0), (0, 1), (1, -1), (1, 0), (1, 1)]
    minimum = 999999999999999

    # 計算最佳的平移方向
    for i in range(9):

        # 平移方向
        dx, dy = bias[i]

        # 將要調整的圖片根據平移的方向與座標進行平移
        nx, ny = x + dx, y + dy
        M = np.float32([[1, 0, nx], [0, 1, ny]])
        cmp_img_aligned = cv2.warpAffine(cmp_img, M, (w, h))
        
        # 計算位移後圖片的 median 並設定 threshold
        cmp_median = np.median(cmp_img_aligned)
        cmp_mtb_img, cmp_mtb = cv2.threshold(cmp_img_aligned, cmp_median, 255, cv2.THRESH_BINARY)

        # 計算平移後的 error
        mask = cv2.inRange(cmp_img, ref_median - threshold, ref_median + threshold)
        mask = cv2.bitwise_not(mask)
        ref_cmp_xor = cv2.bitwise_xor(ref_mtb, cmp_mtb)
        ref_xor_non_mask = cv2.bitwise_and(ref_cmp_xor, mask)
        error = cv2.countNonZero(ref_xor_non_mask)

        if error < minimum:
          minimum = error
          bestx, besty = dx, dy

    return x + bestx, y + besty

def image_alignment(ref_img_path, Output_dir, path, depth, threshold):
  
  ref_img = cv2.imread(ref_img_path, cv2.IMREAD_GRAYSCALE)
  if not os.path.exists(Output_dir):
    os.mkdir(Output_dir)
  k = 0

  path = sorted(glob.glob(path))
  print(path)

  for file in path:
    cmp_img_bgr = cv2.imread(file)
    cmp_img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)

    # 設定初始值
    dx, dy = 0, 0

    # 根據金字塔的深度調整最下層的 image size
    h, w = ref_img.shape[:2]
    for i in range(depth):
      w //= 2
      h //= 2

    center = (w, h)

    # resize image 到最下層金字塔的大小
    ref_img_resize = cv2.resize(ref_img, center)
    cmp_img_resize = cv2.resize(cmp_img, center)

    for i in range(depth):
      # 計算每一層的最佳平移方向
      new_dx, new_dy = MTB(ref_img_resize, cmp_img_resize, dx, dy, threshold)
      # 調整 image size 至上一層的金字塔大小
      w *= 2
      h *= 2
      center = (w, h)
      ref_img_resize = cv2.resize(ref_img, center)
      cmp_img_resize = cv2.resize(cmp_img, center)
      dx = new_dx * 2
      dy = new_dy * 2

    new_dx, new_dy = MTB(ref_img_resize, cmp_img_resize, dx, dy, threshold)

    # 根據計算出的最佳平移方向平移圖片並儲存
    M = np.float32([[1, 0, new_dx], [0, 1, new_dy]])
    cmp_img_aligned = cv2.warpAffine(cmp_img_bgr, M, (w, h))
    cv2.imwrite(os.path.join(f"{Output_dir}",f'{k}'+ "_aligned.JPG"), cmp_img_aligned)
    k+=1

"""
Bilateral Tone mapping
"""

# 引用 https://github.com/OzgurBagci/fastbilateral/blob/master/code/fastbilateralapprox.py


import numpy as np
from scipy import signal, interpolate


def bilateral(image, sigmaspatial, sigmarange, samplespatial=None, samplerange=None):
    """
    :param image: np.array
    :param sigmaspatial: int
    :param sigmarange: int
    :param samplespatial: int || None
    :param samplerange: int || None
    :return: np.array
    Note that sigma values must be integers.
    The 'image' 'np.array' must be given gray-scale. It is suggested that to use OpenCV.
    """

    height = image.shape[0]
    width = image.shape[1]

    samplespatial = sigmaspatial if (samplespatial is None) else samplespatial
    samplerange = sigmarange if (samplerange is None) else samplerange

    flatimage = image.flatten()

    edgemin = np.amin(flatimage)
    edgemax = np.amax(flatimage)
    edgedelta = edgemax - edgemin

    derivedspatial = sigmaspatial / samplespatial
    derivedrange = sigmarange / samplerange

    xypadding = round(2 * derivedspatial + 1)
    zpadding = round(2 * derivedrange + 1)

    samplewidth = int(round((width - 1) / samplespatial) + 1 + 2 * xypadding)
    sampleheight = int(round((height - 1) / samplespatial) + 1 + 2 * xypadding)
    sampledepth = int(round(edgedelta / samplerange) + 1 + 2 * zpadding)

    dataflat = np.zeros(sampleheight * samplewidth * sampledepth)

    (ygrid, xgrid) = np.meshgrid(range(width), range(height))

    dimx = np.around(xgrid / samplespatial) + xypadding
    dimy = np.around(ygrid / samplespatial) + xypadding
    dimz = np.around((image - edgemin) / samplerange) + zpadding

    flatx = dimx.flatten()
    flaty = dimy.flatten()
    flatz = dimz.flatten()

    dim = flatz + flaty * sampledepth + flatx * samplewidth * sampledepth
    dim = np.array(dim, dtype=int)

    dataflat[dim] = flatimage

    data = dataflat.reshape(sampleheight, samplewidth, sampledepth)
    weights = np.array(data, dtype=bool)

    kerneldim = derivedspatial * 2 + 1
    kerneldep = 2 * derivedrange * 2 + 1
    halfkerneldim = round(kerneldim / 2)
    halfkerneldep = round(kerneldep / 2)

    (gridx, gridy, gridz) = np.meshgrid(range(int(kerneldim)), range(int(kerneldim)), range(int(kerneldep)))
    gridx -= int(halfkerneldim)
    gridy -= int(halfkerneldim)
    gridz -= int(halfkerneldep)

    gridsqr = ((gridx * gridx + gridy * gridy) / (derivedspatial * derivedspatial)) \
        + ((gridz * gridz) / (derivedrange * derivedrange))
    kernel = np.exp(-0.5 * gridsqr)

    blurdata = signal.fftconvolve(data, kernel, mode='same')

    blurweights = signal.fftconvolve(weights, kernel, mode='same')
    blurweights = np.where(blurweights == 0, -2, blurweights)

    normalblurdata = blurdata / blurweights
    normalblurdata = np.where(blurweights < -1, 0, normalblurdata)

    (ygrid, xgrid) = np.meshgrid(range(width), range(height))

    dimx = (xgrid / samplespatial) + xypadding
    dimy = (ygrid / samplespatial) + xypadding
    dimz = (image - edgemin) / samplerange + zpadding

    return interpolate.interpn((range(normalblurdata.shape[0]), range(normalblurdata.shape[1]),
                               range(normalblurdata.shape[2])), normalblurdata, (dimx, dimy, dimz))

# fast bilateral filter 實作引用 https://github.com/OzgurBagci/fastbilateral/blob/master/code/fastbilateralapprox.py 
def bilateral_tone(hdr, sigma_s=15, sigma_I=15, gamma=0.5):
  # Normalize
  hdr /= hdr.max()
  e = 0.00000000001
  Illum = 0.114 * hdr[:, :, 0] + 0.587 * hdr[:, :, 1] + 0.299 * hdr[:, :, 2] + e
  log_I = np.log(Illum)
  Blurred = bilateral(log_I,sigma_s, sigma_I)
  # Blurred = cv2.bilateralFilter(log_I, 9 ,150, 7)
  # Blurred = bilateral_filter_own(log_I, 5, 150.0, 150.0)
  detailed = log_I - Blurred
  img_processed = np.exp(gamma * Blurred + detailed)

  ratio = img_processed / (Illum)
  out = hdr * ratio[:, :, np.newaxis]
  out = np.clip(out * 255, 0, 255).astype('uint8')
  cv2.imwrite('tonemap.png', out)

"""Main"""
# dir_path = os.path.dirname(os.path.realpath(__file__))
# os.chdir(dir_path)
Aligned_Output_dir = 'Aligned' #<-若切換Dataset，請重新命名此檔名
PathToData = os.path.join('..','data','ImagesB', '*JPG') # <--調整路徑可調整結果 {ImagesB,ImagesC}
# path = sorted(glob.glob(PathToData))
ref_img_path = os.path.join("..","data","ImagesB","P1011524.JPG") # <--調整路徑可調整結果，設定為所選Data中任意一張影像，我們隨機挑了兩張做為reference {./ImagesB/P1011524.JPG, ./ImagesC/P1011533.JPG}請對應至所選的Data
depth = 4
threshold = 6
image_alignment(ref_img_path, Aligned_Output_dir, PathToData, depth, threshold)

imgs_B, imgs_G, imgs_R = load_img(Aligned_Output_dir)
W_B, Z_B = sample_img(imgs_B)
W_G, Z_G = sample_img(imgs_G)
W_R, Z_R = sample_img(imgs_R)
Shutter_time = [1/500, 1/100, 1/10, 1/5, 1, 1.6, 2.5]
g_b, lE = compute_g_curve(Z_B, Shutter_time, W_B)
g_g, lE = compute_g_curve(Z_G, Shutter_time, W_G)
g_r, lE = compute_g_curve(Z_R, Shutter_time, W_R)
exp_func = np.vectorize(lambda x:math.exp(x))
RadMap_B = comput_radiance(imgs_B, g_b, Shutter_time)      
plt.imshow(RadMap_B, cmap='jet', vmin=-5, vmax=7)
plt.colorbar()
plt.savefig('rad_B.png')
RadMap_G = comput_radiance(imgs_G, g_g, Shutter_time)    
plt.imshow(RadMap_G, cmap='jet', vmin=-5, vmax=7)
plt.savefig('rad_G.png')
RadMap_R = comput_radiance(imgs_R, g_r, Shutter_time)          
plt.imshow(RadMap_R, cmap='jet', vmin=-5, vmax=7)
plt.savefig('rad_R.png')
rad_map = cv2.merge([exp_func(RadMap_B),exp_func(RadMap_G),exp_func(RadMap_R)]).astype(np.float32)
cv2.imwrite('hdr.hdr', rad_map)

bilateral_tone(rad_map,gamma=0.25,sigma_s=150, sigma_I = 150)
